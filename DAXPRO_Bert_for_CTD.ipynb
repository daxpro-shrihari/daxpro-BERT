{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a00762f2-800b-424a-a8e8-58370337281e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-28 15:09:43.974274: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-28 15:09:43.974329: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-28 15:09:44.012660: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-28 15:09:44.087680: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-28 15:09:45.158167: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import logging\n",
    "import hashlib\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# from Python_projects.TextGeneration.lib.CVE2CoA_functions import func_savejson\n",
    "# from functions import group_texts, read2list\n",
    "\n",
    "import torch\n",
    "# from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
    "\n",
    "from huggingface_hub import notebook_login, login, logout\n",
    "from datasets import Dataset, DatasetDict, concatenate_datasets, load_dataset\n",
    "from transformers import TrainingArguments, Trainer, pipeline, DataCollatorForLanguageModeling, DataCollatorWithPadding\n",
    "from transformers import (AutoTokenizer, RobertaTokenizerFast, RobertaForMaskedLM, DataCollatorForLanguageModeling, \n",
    "RobertaForSequenceClassification, Trainer, TrainingArguments)\n",
    "from tokenizers.implementations import ByteLevelBPETokenizer\n",
    "import evaluate\n",
    "\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a017add2-3f6b-4ba1-a8c2-ff545cfa756a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arp.opcode</th>\n",
       "      <th>arp.hw.size</th>\n",
       "      <th>icmp.checksum</th>\n",
       "      <th>icmp.seq_le</th>\n",
       "      <th>icmp.transmit_timestamp</th>\n",
       "      <th>icmp.unused</th>\n",
       "      <th>http.content_length</th>\n",
       "      <th>http.response</th>\n",
       "      <th>http.tls_port</th>\n",
       "      <th>tcp.ack</th>\n",
       "      <th>...</th>\n",
       "      <th>mqtt.len</th>\n",
       "      <th>mqtt.msg_decoded_as</th>\n",
       "      <th>mqtt.msgtype</th>\n",
       "      <th>mqtt.proto_len</th>\n",
       "      <th>mqtt.topic_len</th>\n",
       "      <th>mqtt.ver</th>\n",
       "      <th>mbtcp.len</th>\n",
       "      <th>mbtcp.trans_id</th>\n",
       "      <th>mbtcp.unit_id</th>\n",
       "      <th>Attack_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.219201e+06</td>\n",
       "      <td>2.219201e+06</td>\n",
       "      <td>2.219201e+06</td>\n",
       "      <td>2.219201e+06</td>\n",
       "      <td>2.219201e+06</td>\n",
       "      <td>2219201.0</td>\n",
       "      <td>2.219201e+06</td>\n",
       "      <td>2.219201e+06</td>\n",
       "      <td>2219201.0</td>\n",
       "      <td>2.219201e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>2.219201e+06</td>\n",
       "      <td>2219201.0</td>\n",
       "      <td>2.219201e+06</td>\n",
       "      <td>2.219201e+06</td>\n",
       "      <td>2.219201e+06</td>\n",
       "      <td>2.219201e+06</td>\n",
       "      <td>2.219201e+06</td>\n",
       "      <td>2.219201e+06</td>\n",
       "      <td>2.219201e+06</td>\n",
       "      <td>2.219201e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.323268e-03</td>\n",
       "      <td>1.582732e-02</td>\n",
       "      <td>1.730285e+03</td>\n",
       "      <td>1.893064e+03</td>\n",
       "      <td>2.877556e+03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.808231e+00</td>\n",
       "      <td>1.469132e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.278400e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.982731e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.481643e-01</td>\n",
       "      <td>1.496665e-01</td>\n",
       "      <td>8.977934e-01</td>\n",
       "      <td>1.496665e-01</td>\n",
       "      <td>1.297764e-03</td>\n",
       "      <td>5.170780e-03</td>\n",
       "      <td>9.417804e-05</td>\n",
       "      <td>2.719709e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.843237e-02</td>\n",
       "      <td>3.077555e-01</td>\n",
       "      <td>8.526581e+03</td>\n",
       "      <td>8.870474e+03</td>\n",
       "      <td>4.705188e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.642259e+01</td>\n",
       "      <td>1.203142e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.649033e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>7.648797e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.701086e+00</td>\n",
       "      <td>7.591219e-01</td>\n",
       "      <td>4.554231e+00</td>\n",
       "      <td>7.591219e-01</td>\n",
       "      <td>1.711483e-01</td>\n",
       "      <td>7.226807e-01</td>\n",
       "      <td>1.377313e-02</td>\n",
       "      <td>4.449751e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.900000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>6.553300e+04</td>\n",
       "      <td>6.553500e+04</td>\n",
       "      <td>7.728902e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.365500e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.949529e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>3.900000e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>2.700000e+01</td>\n",
       "      <td>1.510000e+02</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         arp.opcode   arp.hw.size  icmp.checksum   icmp.seq_le  \\\n",
       "count  2.219201e+06  2.219201e+06   2.219201e+06  2.219201e+06   \n",
       "mean   3.323268e-03  1.582732e-02   1.730285e+03  1.893064e+03   \n",
       "std    6.843237e-02  3.077555e-01   8.526581e+03  8.870474e+03   \n",
       "min    0.000000e+00  0.000000e+00   0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00   0.000000e+00  0.000000e+00   \n",
       "50%    0.000000e+00  0.000000e+00   0.000000e+00  0.000000e+00   \n",
       "75%    0.000000e+00  0.000000e+00   0.000000e+00  0.000000e+00   \n",
       "max    2.000000e+00  6.000000e+00   6.553300e+04  6.553500e+04   \n",
       "\n",
       "       icmp.transmit_timestamp  icmp.unused  http.content_length  \\\n",
       "count             2.219201e+06    2219201.0         2.219201e+06   \n",
       "mean              2.877556e+03          0.0         4.808231e+00   \n",
       "std               4.705188e+05          0.0         9.642259e+01   \n",
       "min               0.000000e+00          0.0         0.000000e+00   \n",
       "25%               0.000000e+00          0.0         0.000000e+00   \n",
       "50%               0.000000e+00          0.0         0.000000e+00   \n",
       "75%               0.000000e+00          0.0         0.000000e+00   \n",
       "max               7.728902e+07          0.0         8.365500e+04   \n",
       "\n",
       "       http.response  http.tls_port       tcp.ack  ...      mqtt.len  \\\n",
       "count   2.219201e+06      2219201.0  2.219201e+06  ...  2.219201e+06   \n",
       "mean    1.469132e-02            0.0  2.278400e+07  ...  1.982731e+00   \n",
       "std     1.203142e-01            0.0  1.649033e+08  ...  7.648797e+00   \n",
       "min     0.000000e+00            0.0  0.000000e+00  ...  0.000000e+00   \n",
       "25%     0.000000e+00            0.0  1.000000e+00  ...  0.000000e+00   \n",
       "50%     0.000000e+00            0.0  6.000000e+00  ...  0.000000e+00   \n",
       "75%     0.000000e+00            0.0  5.900000e+01  ...  0.000000e+00   \n",
       "max     1.000000e+00            0.0  3.949529e+09  ...  3.900000e+01   \n",
       "\n",
       "       mqtt.msg_decoded_as  mqtt.msgtype  mqtt.proto_len  mqtt.topic_len  \\\n",
       "count            2219201.0  2.219201e+06    2.219201e+06    2.219201e+06   \n",
       "mean                   0.0  7.481643e-01    1.496665e-01    8.977934e-01   \n",
       "std                    0.0  2.701086e+00    7.591219e-01    4.554231e+00   \n",
       "min                    0.0  0.000000e+00    0.000000e+00    0.000000e+00   \n",
       "25%                    0.0  0.000000e+00    0.000000e+00    0.000000e+00   \n",
       "50%                    0.0  0.000000e+00    0.000000e+00    0.000000e+00   \n",
       "75%                    0.0  0.000000e+00    0.000000e+00    0.000000e+00   \n",
       "max                    0.0  1.400000e+01    4.000000e+00    2.400000e+01   \n",
       "\n",
       "           mqtt.ver     mbtcp.len  mbtcp.trans_id  mbtcp.unit_id  Attack_label  \n",
       "count  2.219201e+06  2.219201e+06    2.219201e+06   2.219201e+06  2.219201e+06  \n",
       "mean   1.496665e-01  1.297764e-03    5.170780e-03   9.417804e-05  2.719709e-01  \n",
       "std    7.591219e-01  1.711483e-01    7.226807e-01   1.377313e-02  4.449751e-01  \n",
       "min    0.000000e+00  0.000000e+00    0.000000e+00   0.000000e+00  0.000000e+00  \n",
       "25%    0.000000e+00  0.000000e+00    0.000000e+00   0.000000e+00  0.000000e+00  \n",
       "50%    0.000000e+00  0.000000e+00    0.000000e+00   0.000000e+00  0.000000e+00  \n",
       "75%    0.000000e+00  0.000000e+00    0.000000e+00   0.000000e+00  1.000000e+00  \n",
       "max    4.000000e+00  2.700000e+01    1.510000e+02   6.000000e+00  1.000000e+00  \n",
       "\n",
       "[8 rows x 43 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/mnt/d/DL_Extra_Data/EdgeIIoT_dataset/DNN-EdgeIIoT-dataset.csv\", low_memory=False)\n",
    "df.head()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d45480e-c435-4369-92c9-834760dd54b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Attack_type    count\n",
      "0                  Normal  1615643\n",
      "1                DDoS_UDP   121568\n",
      "2               DDoS_ICMP   116436\n",
      "3           SQL_injection    51203\n",
      "4                Password    50153\n",
      "5   Vulnerability_scanner    50110\n",
      "6                DDoS_TCP    50062\n",
      "7               DDoS_HTTP    49911\n",
      "8               Uploading    37634\n",
      "9                Backdoor    24862\n",
      "10          Port_Scanning    22564\n",
      "11                    XSS    15915\n",
      "12             Ransomware    10925\n",
      "13                   MITM     1214\n",
      "14         Fingerprinting     1001\n",
      "   Attack_label    count\n",
      "0             0  1615643\n",
      "1             1   603558\n"
     ]
    }
   ],
   "source": [
    "attack_type_counts = df['Attack_type'].value_counts().reset_index()\n",
    "attack_label_counts = df['Attack_label'].value_counts().reset_index()\n",
    "print(attack_type_counts)\n",
    "print(attack_label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "926553f2-bd22-4c0b-bb00-198500990518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type_missing(df):\n",
    "    df_types = pd.DataFrame()\n",
    "    df_types['data_type'] = df.dtypes\n",
    "    df_types['missing_values'] = df.isnull().sum()\n",
    "    df_types['nan_values'] = df.isna().sum()\n",
    "    return df_types.sort_values(by='missing_values', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96337df4-5d0b-4fd4-bc26-4d0966ba3f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_type</th>\n",
       "      <th>missing_values</th>\n",
       "      <th>nan_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>frame.time</th>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mqtt.conflags</th>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tcp.srcport</th>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>udp.port</th>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>udp.stream</th>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tcp.connection.synack</th>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tcp.dstport</th>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tcp.flags</th>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tcp.flags.ack</th>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attack_type</th>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      data_type  missing_values  nan_values\n",
       "frame.time               object               0           0\n",
       "mqtt.conflags           float64               0           0\n",
       "tcp.srcport              object               0           0\n",
       "udp.port                float64               0           0\n",
       "udp.stream              float64               0           0\n",
       "...                         ...             ...         ...\n",
       "tcp.connection.synack   float64               0           0\n",
       "tcp.dstport             float64               0           0\n",
       "tcp.flags               float64               0           0\n",
       "tcp.flags.ack           float64               0           0\n",
       "Attack_type              object               0           0\n",
       "\n",
       "[63 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_type_missing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70a6075e-eee1-47b3-bbeb-1e81dea31903",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = [\"frame.time\", \"ip.src_host\", \"ip.dst_host\", \"arp.src.proto_ipv4\",\"arp.dst.proto_ipv4\",\"http.file_data\",\n",
    "                \"http.request.full_uri\",\"icmp.transmit_timestamp\",\"http.request.uri.query\", \"tcp.options\",\"tcp.payload\",\n",
    "                \"tcp.srcport\",\"tcp.dstport\", \"udp.port\", \"mqtt.msg\", \"icmp.unused\", \"http.tls_port\", 'dns.qry.type', \n",
    "                'dns.retransmit_request_in', \"mqtt.msg_decoded_as\", \"mbtcp.trans_id\", \"mbtcp.unit_id\", \n",
    "                \"http.request.method\", \"http.referer\", \"http.request.version\", \"dns.qry.name.len\", \"mqtt.conack.flags\", \n",
    "                \"mqtt.protoname\", \"mqtt.topic\"]\n",
    "\n",
    "# potential_drop_list = ['arp.opcode']\n",
    "\n",
    "required_columns1 = df.drop(drop_columns, axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe6c05c6-2ba0-4e3c-829c-34eb942b5a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_columns = required_columns1.groupby('Attack_type'\n",
    "                                            ).apply(lambda x: x.sample(n=5000, replace=False) if len(x.index) > 5000 else x\n",
    "                                                   ).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b09c2153-883a-4657-b0c1-887a1758d146",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_llm = pd.DataFrame(columns=['Text', 'Label', 'Type'])\n",
    "df_llm['Text'] = required_columns[required_columns.columns[:-2]].apply(lambda x: x.name+'$'+x.astype(str), \n",
    "                               axis=0).apply(np.vectorize(lambda x: hashlib.shake_256(x.encode(\"utf-8\")).hexdigest(16)), \n",
    "                                             axis=0).agg(' '.join, axis=1)   # df.shape (2219201, 63)\n",
    "# df_llm[['Label', 'Type']] = required_columns[required_columns.columns[[-2,-1]]].iloc[:5000]\n",
    "df_llm[['Label', 'Type']] = required_columns[required_columns.columns[[-2,-1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fe2a025-2bf8-495f-8b64-e140700c7afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, temp_text, train_types, temp_types = train_test_split(df_llm['Text'], df_llm['Type'], \n",
    "                                                                    random_state=2024, \n",
    "                                                                    test_size=0.3, \n",
    "                                                                    stratify=df_llm['Type'])\n",
    "\n",
    "val_text, test_text, val_types, test_types = train_test_split(temp_text, temp_types, \n",
    "                                                                random_state=2024, \n",
    "                                                                test_size=0.5, \n",
    "                                                                stratify=temp_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03af988d-a30a-4146-ba00-d913692c8363",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = pd.concat([train_text, train_types], axis=1\n",
    "                         ).reset_index(drop=True).rename(columns={'Text':'Text','Type':'Label'})\n",
    "val_samples = pd.concat([val_text, val_types], axis=1\n",
    "                         ).reset_index(drop=True).rename(columns={'Text':'Text','Type':'Label'})\n",
    "test_samples = pd.concat([test_text, test_types], axis=1\n",
    "                         ).reset_index(drop=True).rename(columns={'Text':'Text','Type':'Label'})\n",
    "train_samples.to_csv(\"/mnt/d/DL_Extra_Data/EdgeIIoT_dataset/DNN_EdgeIIoT_trainSamples.txt\", sep='\\t', index=False)\n",
    "val_samples.to_csv(\"/mnt/d/DL_Extra_Data/EdgeIIoT_dataset/DNN_EdgeIIoT_valSamples.txt\", sep='\\t', index=False)\n",
    "test_samples.to_csv(\"/mnt/d/DL_Extra_Data/EdgeIIoT_dataset/DNN_EdgeIIoT_testSamples.txt\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bc7a86b-72e5-4337-a467-f0c555967736",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ehsanaghaei/SecureBERT_Plus and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# label2id = dict(sorted(zip(train_types, pd.Categorical(train_types).codes)))\n",
    "id2label = dict(enumerate(pd.Categorical(train_types).categories))\n",
    "label2id = {label:id for id, label in id2label.items()}\n",
    "\n",
    "old_tokenizer = RobertaTokenizerFast.from_pretrained(\"ehsanaghaei/SecureBERT_Plus\")\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"ehsanaghaei/SecureBERT_Plus\", \n",
    "                                                         num_labels=len(train_types.unique().tolist()), \n",
    "                                                         id2label=id2label, #)\n",
    "                                                         label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae75ef0b-af25-428e-a4bd-f2dd981d134f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = {\"train\": Dataset.from_pandas(train_samples), \"validation\": Dataset.from_pandas(val_samples), \n",
    "      \"test\": Dataset.from_pandas(test_samples)}\n",
    "\n",
    "assert ds[\"train\"].features.type == ds[\"validation\"].features.type\n",
    "train_tokens = concatenate_datasets([ds[\"train\"], ds[\"validation\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87f6d11c-733f-430f-a860-5f2cf40bb860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_tokens) is same as len(train_tokens[\"Text\"])\n",
    "def batch_iterator(batch_size=1000):\n",
    "    for i in range(0, len(train_tokens), batch_size):\n",
    "        yield train_tokens[i : i + batch_size][\"Text\"]\n",
    "\n",
    "tokenizer = old_tokenizer.train_new_from_iterator(batch_iterator(), vocab_size=50257, show_progress=True, \n",
    "                                                  length=len(train_tokens[\"Text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "837d7445-884a-4612-b5a4-9b31b9ee604f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(\"./models/DAXPRO_Bert\")\n",
    "del tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50a2768a-ccb6-434d-bcc9-91f6039556d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2df63c72fca4b0ca2af885535fae53c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/47050 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cbe855dde56403ca605a6f45caf717f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10082 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72f589b5fadd41948d4c6ec3dd8f793b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10083 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"./models/DAXPRO_Bert\")\n",
    "\n",
    "def preprocess_function(batch):\n",
    "    label = batch[\"Label\"] \n",
    "    batch = tokenizer(batch[\"Text\"], add_special_tokens=True, truncation=True, padding=\"max_length\", max_length=512)\n",
    "    batch[\"label\"] = LabelEncoder().fit_transform(label)\n",
    "    return batch\n",
    "\n",
    "for split in ds:\n",
    "    ds[split] = ds[split].map(preprocess_function, batched=True, batch_size=24, \n",
    "                              remove_columns=ds[split].column_names)\n",
    "    ds[split].set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])#, \"token_type_ids\"])\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c228e6e-8e1f-4b1a-9cde-6e5969b7d4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"./models/DAXPRO_Bert\",\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"steps\", # \"epoch\",\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=24,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs-securebert',\n",
    "    save_steps=1000, # integer or float (0,1). If float then it saves at the fraction of total training steps.\n",
    "    save_total_limit=2,\n",
    "    logging_steps=1000,\n",
    "    learning_rate=5e-3, # learning_rate=5e-5,\n",
    "    adam_beta2=0.98,\n",
    "    # adam_epsilon=1e-08,\n",
    "    warmup_steps=1500,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    gradient_accumulation_steps=4,\n",
    "    resume_from_checkpoint=True,\n",
    "    load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "914fed3e-9232-42b8-9dbb-ceadd991801d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=ds['train'],\n",
    "    eval_dataset=ds['validation'],\n",
    "    tokenizer=tokenizer\n",
    "    # callbacks=[print_training_loss]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82e7b1d-f213-4615-b652-2065352a5d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec18b256-b514-4ae7-90f8-0de979b55100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "08e2938c-93f0-449f-8284-6c7f02441c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.save_model(\"./models/DAXPRO_Bert\")\n",
    "trainer = Trainer(\n",
    "    model=RobertaForSequenceClassification.from_pretrained(\"./models/DAXPRO_Bert\", \n",
    "                                                         num_labels=len(train_types.unique().tolist()), \n",
    "                                                         id2label=id2label, local_files_only=True,\n",
    "                                                         label2id=label2id),\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=ds['train'],\n",
    "    eval_dataset=ds['validation'],\n",
    "    tokenizer=tokenizer\n",
    "    # callbacks=[print_training_loss]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f67983-b78a-4cec-a9d0-8af11775da5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(ds['test'])\n",
    "print(predictions.predictions.shape, predictions.label_ids.shape)\n",
    "preds = np.argmax(predictions.predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baae5c2-0ba6-49b3-a449-c034cc2b666b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Perplexity: {np.exp(predictions[2]['test_loss']):.2f}\")\n",
    "metric = evaluate.load(\"accuracy\") # \"f1\"\n",
    "# metric = evaluate.load(\"glue\", \"sst2\") # \"mrpc\", \"qqp\"\n",
    "metric.compute(predictions=preds, references=predictions.label_ids)#, average=\"micro\") # \"weighted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3508697e-e65c-4480-af04-8fd90455b812",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "infer = \"f474e674c22006df27f9cb2c87a3286e aa814b6ec204471c80a08a48eb0d7d11 cb330d439a35afb8f4200c404ff7dc2c 0cb57685d860a07580897a9118913cb4 864cd25371de88ed0afea14bf9cb0226 c812a625fbc19e6fdfdf85849076943b 5a070e0da5b668f4a76df165c80194b2 3e87c6b993d75c30120070ebed17f837 fa2c8f87bdb753146bf8cbcfca7d64c1 256b335d13a0129246a0e8d8be3f304d d83e5a9f4a74540ad9390335310d74fb 26c699006bf08c17deffbb647e6c43c7 4edf7b31b7abb70ec768f4e4077bb72c acfeaea6a3afab6d4f27d19ac444ee30 1903e562462530a542a603e57993e02a b5a50e1f80c5144ae2c67c699552a621 c7a3f6310b9c1e8bbbe0a31f4818569c 6de02d23a125f26c5657fe6ad8db4050 ca837062667b0a0daecddd68545a0361 62d797fa4bf445ec38d325cc5bf25801 fe3fbe63218dc71db54afa1e033a1951 dd48fac9a8b720a7cb67884f13a011bf c782773e1f37794735aa48a0af98b8e0 6dd23d8f37bde4625fb6e422290484b6 421032b529029758315ff6a5db11e94f 7271545570cccf7d8b9c2c2bab70ff04 78c05855d80f8795894619cee1dea3d6 317a4c548038e6b51d3433ca96319b88 b0397cae694f13db6da6974b334a9c09 1f7b3ba9490a278bb80eb201afcaae71 8a7ab3742d79b6c691e3f88b4eb1ab33 16c3bc67cf0775dffeef1c37ffad3581\"\n",
    "encoded = tokenizer(infer, add_special_tokens=True, truncation=True, padding=\"max_length\", max_length=512, \n",
    "                    return_tensors=\"pt\").to(device)\n",
    "encoded = {k: v for k,v in encoded.items()}\n",
    "\n",
    "logits = trainer.model(**encoded).logits\n",
    "print(torch.argmax(logits, axis=1))\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e89d50-314c-4c43-9f03-210023fe3347",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_model = \"tiiuae/falcon-7b-instruct\"\n",
    "\n",
    "falcon_tokenizer = AutoTokenizer.from_pretrained(response_model)\n",
    "falcon_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=response_model,\n",
    "    tokenizer=falcon_tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5b3d36-5c4e-48cf-855b-aaf0183df33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = falcon_pipeline(\n",
    "   f\"Our Cyber Security model 'DAXPRO_Bert' detected {id2label[np.argmax(logits.cpu().detach().numpy(), axis=1).item()]} as an attack. Propose security policies and procedures, and provide guidance on best practices for data protection, password management, and social engineering awareness.\",\n",
    "    max_length=200,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=falcon_tokenizer.eos_token_id,\n",
    ")\n",
    "for seq in sequences:\n",
    "    print(f\"Result: {seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b847d2d9-d67c-4da4-933c-9e0d572198a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/cicps/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "login('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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7d487027-1301-44d3-8977-902d8bd31f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/daxproai/daxpro-BERT/commit/99b6959b804f874cf70d83c925c7284f8ca6817f', commit_message='Upload tokenizer', commit_description='', oid='99b6959b804f874cf70d83c925c7284f8ca6817f', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.push_to_hub('daxproai/daxpro-BERT')\n",
    "trainer.model.push_to_hub('daxproai/daxpro-BERT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10b19af-f359-47b2-8a50-85c9fbe9d6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8135725e-431f-48a9-a3d6-800e6ade7aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1afafcf784a46ed9cfad39f7e36aa0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c25cfc037d4344b284c6c169ab701d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06ffc358fc2e48ccb4994684127d6939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/4.66k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/daxproai/DAXPRO_Bert/commit/05ee1cb1565a220491dc84f0815610458c547172', commit_message='daxproai/daxpro-BERT', commit_description='', oid='05ee1cb1565a220491dc84f0815610458c547172', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub('daxproai/daxpro-BERT') # This pushes everything model and tokenzier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13814a26-dd31-47b1-9567-a3de39686f83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
